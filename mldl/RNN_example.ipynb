{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"958ow1teGxa0"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical #one hot encoding"]},{"cell_type":"code","source":["text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n","그의 말이 법이다\\n\n","가는 말이 고와야 오는 말이 곱다\\n\"\"\""],"metadata":{"id":"OBchaM4zGx0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","vocab_size = len(tokenizer.word_index) + 1\n","print('단어 집합의 크기 : %d' % vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LAx5znyGzVK","outputId":"83712acf-77ab-4999-eeec-09e9c7d9e80d","executionInfo":{"status":"ok","timestamp":1665560623882,"user_tz":-540,"elapsed":5,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기 : 12\n"]}]},{"cell_type":"code","source":["print(tokenizer.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9qP-rYnG9nK","outputId":"227b230e-5efe-4631-f147-794afa59c165","executionInfo":{"status":"ok","timestamp":1665560626155,"user_tz":-540,"elapsed":16,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"]}]},{"cell_type":"code","source":["sequences = list()\n","for line in text.split('\\n'): # 줄바꿈 문자를 기준으로 문장 토큰화\n","    encoded = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(encoded)):\n","        sequence = encoded[:i+1]\n","        sequences.append(sequence)\n","\n","print('학습에 사용할 샘플의 개수: %d' % len(sequences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fe3ZBGbhG_B9","outputId":"040264ae-da42-4180-9751-90008c21c08b","executionInfo":{"status":"ok","timestamp":1665560629665,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["학습에 사용할 샘플의 개수: 11\n"]}]},{"cell_type":"code","source":["print(sequences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RKJsFoeHAei","outputId":"85072888-096d-48d0-89ef-93e7d209f9ba","executionInfo":{"status":"ok","timestamp":1665560632854,"user_tz":-540,"elapsed":336,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"]}]},{"cell_type":"code","source":["max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n","print('샘플의 최대 길이 : {}'.format(max_len))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8Y43bMYHB57","outputId":"f2287d82-c68d-4156-eb87-f74f1379f12a","executionInfo":{"status":"ok","timestamp":1665560636051,"user_tz":-540,"elapsed":2,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["샘플의 최대 길이 : 6\n"]}]},{"cell_type":"code","source":["sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"],"metadata":{"id":"UNWvK93aHJBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sequences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUlLbDM3HJ8k","outputId":"67147cd1-a022-4e81-c9e8-9231df121ace","executionInfo":{"status":"ok","timestamp":1665560641077,"user_tz":-540,"elapsed":616,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  0  2  3]\n"," [ 0  0  0  2  3  1]\n"," [ 0  0  2  3  1  4]\n"," [ 0  2  3  1  4  5]\n"," [ 0  0  0  0  6  1]\n"," [ 0  0  0  6  1  7]\n"," [ 0  0  0  0  8  1]\n"," [ 0  0  0  8  1  9]\n"," [ 0  0  8  1  9 10]\n"," [ 0  8  1  9 10  1]\n"," [ 8  1  9 10  1 11]]\n"]}]},{"cell_type":"code","source":["sequences = np.array(sequences)\n","X = sequences[:,:-1]\n","y = sequences[:,-1]"],"metadata":{"id":"2IuhLdFXHLQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X03JnNsGHMeE","outputId":"2a895e77-a41f-4ef1-bc70-8f8af97f7b87","executionInfo":{"status":"ok","timestamp":1665560648476,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  0  2]\n"," [ 0  0  0  2  3]\n"," [ 0  0  2  3  1]\n"," [ 0  2  3  1  4]\n"," [ 0  0  0  0  6]\n"," [ 0  0  0  6  1]\n"," [ 0  0  0  0  8]\n"," [ 0  0  0  8  1]\n"," [ 0  0  8  1  9]\n"," [ 0  8  1  9 10]\n"," [ 8  1  9 10  1]]\n"]}]},{"cell_type":"code","source":["print(y)"],"metadata":{"id":"mT4Fw4xGHNq8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665560651964,"user_tz":-540,"elapsed":318,"user":{"displayName":"김성식","userId":"17836563048180576470"}},"outputId":"15e0de36-4356-4196-ffec-50bba698dbe8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 3  1  4  5  1  7  1  9 10  1 11]\n"]}]},{"cell_type":"code","source":["y = to_categorical(y, num_classes=vocab_size) # one hot encoding"],"metadata":{"id":"qxY947UjHO0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, SimpleRNN # dense = 일반적인 뉴렬네트워크"],"metadata":{"id":"68ZBwjNDHQFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 10 #입력 단어들의 임베딩\n","hidden_units = 32 #네트워크 크기를 지정\n","\n","model = Sequential() # 레이어를 더한 순서대로 입력이 들어가는 형태\n","model.add(Embedding(vocab_size, embedding_dim)) #단어들이 임베딩 됨. => 10 차원 벡터\n","model.add(SimpleRNN(hidden_units)) # RNN 각각 \n","model.add(Dense(vocab_size, activation='softmax')) #\n","\n","########### 모델을 정의하는 부분 끝 ###############\n","\n","########### 모델을 학습하는 부분 #################\n","model.compile(loss='categorical_crossentropy' # 분류문제를 풀 때 쓰는 loss 함수\n",", optimizer='adam' # 미분 방법\n",", metrics=['accuracy'] # 모델을 인간이 평가할 때, 어떤 지표를 쓸 것인가 0-1 => 1 이면 100%\n",")\n","model.fit(X, y, epochs=200, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NOeWjmBHRk8","outputId":"705c181b-e8cb-4109-9689-e2191f4ff4a8","executionInfo":{"status":"ok","timestamp":1665560667741,"user_tz":-540,"elapsed":6880,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","1/1 - 1s - loss: 2.4681 - accuracy: 0.2727 - 1s/epoch - 1s/step\n","Epoch 2/200\n","1/1 - 0s - loss: 2.4568 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 3/200\n","1/1 - 0s - loss: 2.4452 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n","Epoch 4/200\n","1/1 - 0s - loss: 2.4332 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n","Epoch 5/200\n","1/1 - 0s - loss: 2.4209 - accuracy: 0.5455 - 16ms/epoch - 16ms/step\n","Epoch 6/200\n","1/1 - 0s - loss: 2.4080 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n","Epoch 7/200\n","1/1 - 0s - loss: 2.3945 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n","Epoch 8/200\n","1/1 - 0s - loss: 2.3803 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 9/200\n","1/1 - 0s - loss: 2.3653 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 10/200\n","1/1 - 0s - loss: 2.3494 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n","Epoch 11/200\n","1/1 - 0s - loss: 2.3326 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 12/200\n","1/1 - 0s - loss: 2.3149 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 13/200\n","1/1 - 0s - loss: 2.2961 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n","Epoch 14/200\n","1/1 - 0s - loss: 2.2762 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 15/200\n","1/1 - 0s - loss: 2.2553 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 16/200\n","1/1 - 0s - loss: 2.2333 - accuracy: 0.3636 - 12ms/epoch - 12ms/step\n","Epoch 17/200\n","1/1 - 0s - loss: 2.2104 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 18/200\n","1/1 - 0s - loss: 2.1865 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 19/200\n","1/1 - 0s - loss: 2.1619 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 20/200\n","1/1 - 0s - loss: 2.1366 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 21/200\n","1/1 - 0s - loss: 2.1111 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 22/200\n","1/1 - 0s - loss: 2.0854 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 23/200\n","1/1 - 0s - loss: 2.0601 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 24/200\n","1/1 - 0s - loss: 2.0356 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 25/200\n","1/1 - 0s - loss: 2.0122 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 26/200\n","1/1 - 0s - loss: 1.9903 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 27/200\n","1/1 - 0s - loss: 1.9702 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 28/200\n","1/1 - 0s - loss: 1.9522 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 29/200\n","1/1 - 0s - loss: 1.9362 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n","Epoch 30/200\n","1/1 - 0s - loss: 1.9220 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 31/200\n","1/1 - 0s - loss: 1.9091 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 32/200\n","1/1 - 0s - loss: 1.8970 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n","Epoch 33/200\n","1/1 - 0s - loss: 1.8852 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 34/200\n","1/1 - 0s - loss: 1.8733 - accuracy: 0.3636 - 14ms/epoch - 14ms/step\n","Epoch 35/200\n","1/1 - 0s - loss: 1.8608 - accuracy: 0.3636 - 10ms/epoch - 10ms/step\n","Epoch 36/200\n","1/1 - 0s - loss: 1.8476 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 37/200\n","1/1 - 0s - loss: 1.8338 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 38/200\n","1/1 - 0s - loss: 1.8195 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n","Epoch 39/200\n","1/1 - 0s - loss: 1.8050 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 40/200\n","1/1 - 0s - loss: 1.7905 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 41/200\n","1/1 - 0s - loss: 1.7761 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 42/200\n","1/1 - 0s - loss: 1.7621 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n","Epoch 43/200\n","1/1 - 0s - loss: 1.7483 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n","Epoch 44/200\n","1/1 - 0s - loss: 1.7347 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 45/200\n","1/1 - 0s - loss: 1.7212 - accuracy: 0.3636 - 11ms/epoch - 11ms/step\n","Epoch 46/200\n","1/1 - 0s - loss: 1.7076 - accuracy: 0.3636 - 8ms/epoch - 8ms/step\n","Epoch 47/200\n","1/1 - 0s - loss: 1.6937 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n","Epoch 48/200\n","1/1 - 0s - loss: 1.6794 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n","Epoch 49/200\n","1/1 - 0s - loss: 1.6646 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n","Epoch 50/200\n","1/1 - 0s - loss: 1.6492 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n","Epoch 51/200\n","1/1 - 0s - loss: 1.6334 - accuracy: 0.4545 - 9ms/epoch - 9ms/step\n","Epoch 52/200\n","1/1 - 0s - loss: 1.6171 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n","Epoch 53/200\n","1/1 - 0s - loss: 1.6005 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 54/200\n","1/1 - 0s - loss: 1.5835 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n","Epoch 55/200\n","1/1 - 0s - loss: 1.5663 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n","Epoch 56/200\n","1/1 - 0s - loss: 1.5488 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n","Epoch 57/200\n","1/1 - 0s - loss: 1.5310 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n","Epoch 58/200\n","1/1 - 0s - loss: 1.5130 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n","Epoch 59/200\n","1/1 - 0s - loss: 1.4946 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n","Epoch 60/200\n","1/1 - 0s - loss: 1.4758 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n","Epoch 61/200\n","1/1 - 0s - loss: 1.4567 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n","Epoch 62/200\n","1/1 - 0s - loss: 1.4373 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n","Epoch 63/200\n","1/1 - 0s - loss: 1.4175 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n","Epoch 64/200\n","1/1 - 0s - loss: 1.3976 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n","Epoch 65/200\n","1/1 - 0s - loss: 1.3775 - accuracy: 0.5455 - 24ms/epoch - 24ms/step\n","Epoch 66/200\n","1/1 - 0s - loss: 1.3574 - accuracy: 0.6364 - 15ms/epoch - 15ms/step\n","Epoch 67/200\n","1/1 - 0s - loss: 1.3372 - accuracy: 0.6364 - 18ms/epoch - 18ms/step\n","Epoch 68/200\n","1/1 - 0s - loss: 1.3172 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n","Epoch 69/200\n","1/1 - 0s - loss: 1.2972 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n","Epoch 70/200\n","1/1 - 0s - loss: 1.2773 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n","Epoch 71/200\n","1/1 - 0s - loss: 1.2576 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n","Epoch 72/200\n","1/1 - 0s - loss: 1.2380 - accuracy: 0.6364 - 10ms/epoch - 10ms/step\n","Epoch 73/200\n","1/1 - 0s - loss: 1.2186 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 74/200\n","1/1 - 0s - loss: 1.1994 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n","Epoch 75/200\n","1/1 - 0s - loss: 1.1804 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n","Epoch 76/200\n","1/1 - 0s - loss: 1.1617 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n","Epoch 77/200\n","1/1 - 0s - loss: 1.1433 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n","Epoch 78/200\n","1/1 - 0s - loss: 1.1252 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n","Epoch 79/200\n","1/1 - 0s - loss: 1.1075 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n","Epoch 80/200\n","1/1 - 0s - loss: 1.0901 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n","Epoch 81/200\n","1/1 - 0s - loss: 1.0731 - accuracy: 0.6364 - 8ms/epoch - 8ms/step\n","Epoch 82/200\n","1/1 - 0s - loss: 1.0564 - accuracy: 0.6364 - 17ms/epoch - 17ms/step\n","Epoch 83/200\n","1/1 - 0s - loss: 1.0400 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n","Epoch 84/200\n","1/1 - 0s - loss: 1.0240 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 85/200\n","1/1 - 0s - loss: 1.0082 - accuracy: 0.6364 - 17ms/epoch - 17ms/step\n","Epoch 86/200\n","1/1 - 0s - loss: 0.9928 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n","Epoch 87/200\n","1/1 - 0s - loss: 0.9776 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n","Epoch 88/200\n","1/1 - 0s - loss: 0.9627 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n","Epoch 89/200\n","1/1 - 0s - loss: 0.9481 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n","Epoch 90/200\n","1/1 - 0s - loss: 0.9337 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n","Epoch 91/200\n","1/1 - 0s - loss: 0.9196 - accuracy: 0.7273 - 22ms/epoch - 22ms/step\n","Epoch 92/200\n","1/1 - 0s - loss: 0.9057 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n","Epoch 93/200\n","1/1 - 0s - loss: 0.8920 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n","Epoch 94/200\n","1/1 - 0s - loss: 0.8786 - accuracy: 0.7273 - 38ms/epoch - 38ms/step\n","Epoch 95/200\n","1/1 - 0s - loss: 0.8654 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n","Epoch 96/200\n","1/1 - 0s - loss: 0.8524 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n","Epoch 97/200\n","1/1 - 0s - loss: 0.8396 - accuracy: 0.7273 - 19ms/epoch - 19ms/step\n","Epoch 98/200\n","1/1 - 0s - loss: 0.8271 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n","Epoch 99/200\n","1/1 - 0s - loss: 0.8147 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n","Epoch 100/200\n","1/1 - 0s - loss: 0.8025 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n","Epoch 101/200\n","1/1 - 0s - loss: 0.7905 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n","Epoch 102/200\n","1/1 - 0s - loss: 0.7787 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n","Epoch 103/200\n","1/1 - 0s - loss: 0.7670 - accuracy: 0.7273 - 24ms/epoch - 24ms/step\n","Epoch 104/200\n","1/1 - 0s - loss: 0.7555 - accuracy: 0.7273 - 17ms/epoch - 17ms/step\n","Epoch 105/200\n","1/1 - 0s - loss: 0.7441 - accuracy: 0.7273 - 13ms/epoch - 13ms/step\n","Epoch 106/200\n","1/1 - 0s - loss: 0.7329 - accuracy: 0.7273 - 23ms/epoch - 23ms/step\n","Epoch 107/200\n","1/1 - 0s - loss: 0.7218 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n","Epoch 108/200\n","1/1 - 0s - loss: 0.7108 - accuracy: 0.7273 - 13ms/epoch - 13ms/step\n","Epoch 109/200\n","1/1 - 0s - loss: 0.7000 - accuracy: 0.7273 - 16ms/epoch - 16ms/step\n","Epoch 110/200\n","1/1 - 0s - loss: 0.6892 - accuracy: 0.7273 - 14ms/epoch - 14ms/step\n","Epoch 111/200\n","1/1 - 0s - loss: 0.6786 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n","Epoch 112/200\n","1/1 - 0s - loss: 0.6681 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n","Epoch 113/200\n","1/1 - 0s - loss: 0.6578 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n","Epoch 114/200\n","1/1 - 0s - loss: 0.6475 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n","Epoch 115/200\n","1/1 - 0s - loss: 0.6373 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n","Epoch 116/200\n","1/1 - 0s - loss: 0.6272 - accuracy: 0.8182 - 13ms/epoch - 13ms/step\n","Epoch 117/200\n","1/1 - 0s - loss: 0.6173 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 118/200\n","1/1 - 0s - loss: 0.6074 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n","Epoch 119/200\n","1/1 - 0s - loss: 0.5977 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n","Epoch 120/200\n","1/1 - 0s - loss: 0.5880 - accuracy: 0.8182 - 10ms/epoch - 10ms/step\n","Epoch 121/200\n","1/1 - 0s - loss: 0.5785 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n","Epoch 122/200\n","1/1 - 0s - loss: 0.5691 - accuracy: 0.9091 - 11ms/epoch - 11ms/step\n","Epoch 123/200\n","1/1 - 0s - loss: 0.5598 - accuracy: 0.9091 - 14ms/epoch - 14ms/step\n","Epoch 124/200\n","1/1 - 0s - loss: 0.5506 - accuracy: 0.9091 - 14ms/epoch - 14ms/step\n","Epoch 125/200\n","1/1 - 0s - loss: 0.5415 - accuracy: 0.9091 - 13ms/epoch - 13ms/step\n","Epoch 126/200\n","1/1 - 0s - loss: 0.5325 - accuracy: 0.9091 - 19ms/epoch - 19ms/step\n","Epoch 127/200\n","1/1 - 0s - loss: 0.5236 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n","Epoch 128/200\n","1/1 - 0s - loss: 0.5148 - accuracy: 0.9091 - 14ms/epoch - 14ms/step\n","Epoch 129/200\n","1/1 - 0s - loss: 0.5062 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n","Epoch 130/200\n","1/1 - 0s - loss: 0.4977 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n","Epoch 131/200\n","1/1 - 0s - loss: 0.4893 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n","Epoch 132/200\n","1/1 - 0s - loss: 0.4810 - accuracy: 0.9091 - 18ms/epoch - 18ms/step\n","Epoch 133/200\n","1/1 - 0s - loss: 0.4728 - accuracy: 0.9091 - 13ms/epoch - 13ms/step\n","Epoch 134/200\n","1/1 - 0s - loss: 0.4648 - accuracy: 0.9091 - 21ms/epoch - 21ms/step\n","Epoch 135/200\n","1/1 - 0s - loss: 0.4568 - accuracy: 0.9091 - 12ms/epoch - 12ms/step\n","Epoch 136/200\n","1/1 - 0s - loss: 0.4490 - accuracy: 0.9091 - 14ms/epoch - 14ms/step\n","Epoch 137/200\n","1/1 - 0s - loss: 0.4413 - accuracy: 0.9091 - 23ms/epoch - 23ms/step\n","Epoch 138/200\n","1/1 - 0s - loss: 0.4338 - accuracy: 0.9091 - 33ms/epoch - 33ms/step\n","Epoch 139/200\n","1/1 - 0s - loss: 0.4263 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n","Epoch 140/200\n","1/1 - 0s - loss: 0.4190 - accuracy: 0.9091 - 32ms/epoch - 32ms/step\n","Epoch 141/200\n","1/1 - 0s - loss: 0.4118 - accuracy: 0.9091 - 13ms/epoch - 13ms/step\n","Epoch 142/200\n","1/1 - 0s - loss: 0.4047 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n","Epoch 143/200\n","1/1 - 0s - loss: 0.3977 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n","Epoch 144/200\n","1/1 - 0s - loss: 0.3909 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n","Epoch 145/200\n","1/1 - 0s - loss: 0.3842 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n","Epoch 146/200\n","1/1 - 0s - loss: 0.3776 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n","Epoch 147/200\n","1/1 - 0s - loss: 0.3711 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n","Epoch 148/200\n","1/1 - 0s - loss: 0.3647 - accuracy: 0.9091 - 18ms/epoch - 18ms/step\n","Epoch 149/200\n","1/1 - 0s - loss: 0.3584 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n","Epoch 150/200\n","1/1 - 0s - loss: 0.3522 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n","Epoch 151/200\n","1/1 - 0s - loss: 0.3462 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n","Epoch 152/200\n","1/1 - 0s - loss: 0.3403 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n","Epoch 153/200\n","1/1 - 0s - loss: 0.3344 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n","Epoch 154/200\n","1/1 - 0s - loss: 0.3287 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 155/200\n","1/1 - 0s - loss: 0.3231 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 156/200\n","1/1 - 0s - loss: 0.3176 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 157/200\n","1/1 - 0s - loss: 0.3121 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n","Epoch 158/200\n","1/1 - 0s - loss: 0.3068 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 159/200\n","1/1 - 0s - loss: 0.3016 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 160/200\n","1/1 - 0s - loss: 0.2965 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n","Epoch 161/200\n","1/1 - 0s - loss: 0.2915 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n","Epoch 162/200\n","1/1 - 0s - loss: 0.2865 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 163/200\n","1/1 - 0s - loss: 0.2817 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 164/200\n","1/1 - 0s - loss: 0.2770 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n","Epoch 165/200\n","1/1 - 0s - loss: 0.2723 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n","Epoch 166/200\n","1/1 - 0s - loss: 0.2677 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n","Epoch 167/200\n","1/1 - 0s - loss: 0.2632 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n","Epoch 168/200\n","1/1 - 0s - loss: 0.2588 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n","Epoch 169/200\n","1/1 - 0s - loss: 0.2545 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 170/200\n","1/1 - 0s - loss: 0.2503 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 171/200\n","1/1 - 0s - loss: 0.2461 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 172/200\n","1/1 - 0s - loss: 0.2420 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 173/200\n","1/1 - 0s - loss: 0.2380 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 174/200\n","1/1 - 0s - loss: 0.2341 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 175/200\n","1/1 - 0s - loss: 0.2303 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 176/200\n","1/1 - 0s - loss: 0.2265 - accuracy: 1.0000 - 13ms/epoch - 13ms/step\n","Epoch 177/200\n","1/1 - 0s - loss: 0.2228 - accuracy: 1.0000 - 12ms/epoch - 12ms/step\n","Epoch 178/200\n","1/1 - 0s - loss: 0.2191 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 179/200\n","1/1 - 0s - loss: 0.2156 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 180/200\n","1/1 - 0s - loss: 0.2121 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 181/200\n","1/1 - 0s - loss: 0.2086 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 182/200\n","1/1 - 0s - loss: 0.2053 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 183/200\n","1/1 - 0s - loss: 0.2019 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 184/200\n","1/1 - 0s - loss: 0.1987 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 185/200\n","1/1 - 0s - loss: 0.1955 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 186/200\n","1/1 - 0s - loss: 0.1924 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 187/200\n","1/1 - 0s - loss: 0.1893 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 188/200\n","1/1 - 0s - loss: 0.1863 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n","Epoch 189/200\n","1/1 - 0s - loss: 0.1833 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 190/200\n","1/1 - 0s - loss: 0.1804 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 191/200\n","1/1 - 0s - loss: 0.1776 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n","Epoch 192/200\n","1/1 - 0s - loss: 0.1748 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 193/200\n","1/1 - 0s - loss: 0.1721 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n","Epoch 194/200\n","1/1 - 0s - loss: 0.1694 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n","Epoch 195/200\n","1/1 - 0s - loss: 0.1667 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 196/200\n","1/1 - 0s - loss: 0.1641 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n","Epoch 197/200\n","1/1 - 0s - loss: 0.1616 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 198/200\n","1/1 - 0s - loss: 0.1591 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 199/200\n","1/1 - 0s - loss: 0.1566 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n","Epoch 200/200\n","1/1 - 0s - loss: 0.1542 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f927de13950>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n","    init_word = current_word\n","    sentence = ''\n","\n","    # n번 반복\n","    for _ in range(n):\n","        # 현재 단어에 대한 정수 인코딩과 패딩\n","        encoded = tokenizer.texts_to_sequences([current_word])[0]\n","        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n","        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n","        result = model.predict(encoded, verbose=0)\n","        result = np.argmax(result, axis=1)\n","\n","        for word, index in tokenizer.word_index.items(): \n","            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n","            if index == result:\n","                break\n","\n","        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n","        current_word = current_word + ' '  + word\n","\n","        # 예측 단어를 문장에 저장\n","        sentence = sentence + ' ' + word\n","\n","    sentence = init_word + sentence\n","    return sentence"],"metadata":{"id":"lDzyxAuFHTC1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sentence_generation(model, tokenizer, '경마장에', ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"BJF8B0dNHV1E","outputId":"505c290f-aba6-4684-dbbd-abc895cebfff","executionInfo":{"status":"error","timestamp":1665625030654,"user_tz":-540,"elapsed":13,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3bfc0583aab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'경마장에'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'sentence_generation' is not defined"]}]},{"cell_type":"code","source":["print(sentence_generation(model, tokenizer, '그의', 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sdfc3omHYDE","outputId":"95229595-f940-4551-9fdc-46cec9b41986","executionInfo":{"status":"ok","timestamp":1665562721358,"user_tz":-540,"elapsed":324,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["그의 말이 법이다\n"]}]},{"cell_type":"code","source":["print(sentence_generation(model, tokenizer, '가는', 5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MtXkzQYUHb39","outputId":"ed69b767-f6dd-430c-a622-1fc729e884ae","executionInfo":{"status":"ok","timestamp":1665562718524,"user_tz":-540,"elapsed":665,"user":{"displayName":"김성식","userId":"17836563048180576470"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["가는 말이 고와야 오는 말이 곱다\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mO09QGMSHdqV"},"execution_count":null,"outputs":[]}]}
